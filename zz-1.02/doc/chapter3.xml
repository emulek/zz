<chapter id="chapter3"><title>Использование</title>
	<section><title>Надёжность и избыточность</title>
		<section>
			<para>
				Безусловно, чем выше избыточность, тем лучше надёжность. Однако остаётся вопрос
				"насколько выше?".
			</para>
			<para><anchor id="pb" />
				Предположим, что у нас имеется файл, разделённый на 7 блоков. Обозначим вероятность сбоя файла как
				p(f), а вероятность сбоя блока как p(b).
				<tip>
					<para>
						Термин <emphasis>вероятность сбоя</emphasis> здесь понимается как вероятность того печального
						события, когда мы не смогли правильно прочитать информацию.
						Т.е. если вероятность сбоя равна 1%, то в среднем из 100 чтений одно будет неудачным. Подразумевается,
						что повторное чтение(в случае сбоя) либо невозможно, либо даст тоже неверный результат —
						умерла, так умерла.
					</para>
					<para>
						А термин <emphasis>надёжность</emphasis> означает вероятность обратного события, т.е. если вероятность
						сбоя равна 1%, то надёжность составляет 100%-1%=99%.
					</para>
				</tip>
			</para>
			<para>
				Очевидно, что при семи блоках, вероятность сбоя всего файла в семь раз выше вероятности сбоя блока.
				<note>
					Я предполагаю, что вероятность сбоя достаточно мала.
				</note>
				Причина этого в том, что файл будет испорчен при порче любого из блоков.
			</para>
			<para>
				Что-же произойдёт при введении избыточности? Это видно на графиках:
			</para>
			<para>
				<mediaobject><imageobject><imagedata fileref="448.png" format="png" />
				</imageobject></mediaobject>
				Тут по оси абссцисс обозначена вероятность сбоя блока p(b), а по оси ординат — всего файла p(f).
			</para>
			<para>
				Тут видно, что если p(b) меньше 5%, то p(f) практически 0%
				<caution>
					<para>
						Но НЕ ноль. Так, если p(b)=0.5%, то p(f)=0.001%. Т.е. даже если надёжность блоков близка к 100%,
						надёжность файлов НЕ достигает 100%, хотя и намного больше надёжности одного блока.
					</para>
					<para>
						Таким образом, ещё раз доказано, что 100% гарантии даёт лишь мёртвая система.
					</para>
				</caution>
				В итоге, при высокой надёжности блоков, надёжность всего файла многократно повышается, и чем надёжнее блок,
				тем больше повышение надёжности файла.
			</para>
			<para>
				Однако, после p(b)=5%, надёжность начинает сильно падать. Здесь p(b)=p(f) примерно на 15%, и с ростом p(b),
				p(f) возрастает ещё быстрее, намного быстрее, чем в том случае, если-бы избыточности небыло.
			</para>
			<para>
				В итоге мы имеем интересный эффект: если принять, что p(b) линейно растёт с течением времени (например из-за деградации
				флеш-памяти), то без избыточности это привело-бы также к линейному уменьшению рабочих блоков. Но с избыточностью
				картина иная: первое время потеря блоков абсолютно незаметна (конечно при наличии достаточного резерва, у меня тут
				2 резервных блока на 7 основных), затем, число сбойных блоков ВНЕЗАПНО увеличивается, приводя в негодность устройство
				хранения или канал передачи.
				<note>
					Это, кстати, определило выбор именно <link linkend="system_encode">несистематического кодирования</link>.
					Ещё одна проблема систематического кодирования заключается во времени: если ошибок почти нет, то время
					декодирования практически нулевое. Но оно очень сильно возрастает, если ошибок достаточно много. Это важно в
					случае передачи блоков с высокой избыточностью и наличием обратной связи: доноры отправляют все блоки,
					но реципиент принимает лишь те, которые ему проще принять. Набор этих блоков у донора совершенно произвольный,
					и вероятность того, что ими окажутся именно первые блоки c₀,c₁,c₂… ничтожна. Потому в общем случае набор блоков
					совершенно произвольный. На практике это тоже часто встречается, мало того, позволяет использовать
					данный кодер там, где другие кодеры не эффективны.
				</note>
			</para>
		</section>
	</section>
	<section><title>Хранение файлов</title>
		<para>
			Очевидно, самое простое использование данной программы заключается в хранении файла на ненадёжном носителе(носителях),
			сюда же относится случай кеширования файлов.
		</para>
		<section><title>Единственное хранилище</title>
			<para>
				Если мы имеем единственное хранилище, объём которого больше объёма файла, то вполне естественно заполнить
				свободное место резервной информацией.
			</para>
			<para>
				К примеру, имея <link linkend="pb">p(b)</link>=1% и файл из 7и блоков, p(f) получается около 7% (точнее 6.723%). Добавив
				восьмой блок получаем p(f) уже 0.27%, а если добавить ещё один(7+2), получится всего 0.01%. Т.о. при увеличении
				занимаемого размера до 129%, вероятность потери уменьшается в 100 раз.
			</para>
		</section>
		<section><title>Несколько хранилищ</title>
			<para>
				Также полезно разбивать файл на несколько хранилищ, если существует опасность потерять какое-то хранилище целиком.
			</para>
			<para>
				Правда с двумя хранилищами это ничем не лучше резервирования(если конечно хранилища имееют надёжность 100%).
				Однако, уже при 3х хранилищах, мы можем использовать схему в 4 блока данных + 2 дополнительных. В каждом хранилище
				будет 2 блока (⅔ файла), и для гарантированного восстановления понадобится всего 2 из трёх хранилищ.
			</para>
			<para>
				Особенно это будет полезно, если файлов несколько, и имеется удалённое(сетевое, например облако) хранилище. В этом случае
				мы можем использовать всего одно хранилище например размером 1Гб, для хранения файла размером 1.4Гб (в сетевом хранилище
				этот файл будет целиком). Тогда для получения всего файла понадобится выкачать 0.4Гб из сетевого хранилища, но если
				файлов несколько, то и качать нужно будет в среднем 40% файла. При этом выбор конкретных блоков в хранилище
				значения не имеет. Последнее очень важно, т.к. файлы в локальном хранилище можно удалять не глядя, например в порядке
				их SHA1. Порядок удаления никак не повлияет на среднюю скорость и средний объём закаченного с удалённого хранилища.
			</para>
			<para>
				Т.е. если нам нужно освободить в локальном хранилище 100Мб, мы можем удалить первые 100Мб блоков, это приведёт только
				к тому, что для получения нашего файла в 1.4Гб потребуется выкачать 500Мб из удалённого хранилища. Естественно,
				мы можем потом(когда у нас появится св. место) закачать из хранилища скажем 200Мб новых блоков, и тогда для получения
				1.4Гб-ного файла потребуется выкачать всего 300Мб, т.к. в хранилище у нас уже 1100Мб.
				<note>
					Всё это конечно верно во первых только в среднем, нам может и не повезти, и из удалённого хранилища придётся
					качать несколько больше Мб, а во вторых, это всё математическое ожидание, и работает это лишь при достаточно
					мелких блоках(т.е. одна часть должна быть хотя-бы 1/10 всего файла). Если блоки крупные, то велика
					вероятность коллизии, при которой мы удаляем не по 1 блоку из части, а в некоторых случаях по 2. Это несколько
					портит статистику(если нам не повезло).
				</note>
			</para>
		</section>
		<section><title>Кеширование</title>
			<para>
				Обычное кеширование работает на уровне файлов, потому обладает существенным недостатком, в случае, если файлы разные:
				к примеру, если стратегия кеширования решает удалить "ненужный" файл в 1000Мб для сохранения "нужного" в 100Мб,
				то получается дырка размером 900Мб. Используя избыточное кодирование можно более точно работать с кешем, удалять
				не весь "ненужный" файл в 1000Мб, а лишь 100Мб из него. Тогда, если "ненужный" файл станет "нужным", извлекать в
				кеш придёться лишь недостающие 100Мб. Такая система кеширования работает намного устойчивее, и очень нравится
				юзера(юзеры могут простить "задумчивость" системы, когда она тормозит "по делу", но ненавидят, когда
				система ВНЕЗАПНО "зависает", без всяких видимых причин).
			</para>
			<para>
				Кроме того, многие ФС монтируют с noatime, что приводит к невозможности сбора статистики и кеширования(т.к.
				система не знает, когда файл был в последний раз "нужен"). В таком случае можно также использовать избыточность,
				сохранять файлы с большой избыточностью(например 214%), а удалять блоки в случайном порядке. Если нужен доступ к файлу,
				система дополняет его до 214%(если осталось меньше 100%, то извлекает блоки из основного хранилища). Через некоторое время,
				избыточность "нужных" файлов установится достаточно большой, а "не нужные" будут автоматически вытесняться из
				хранилища.
			</para>
		</section>
	</section>
	<section><title>Передача файлов по Сети</title>
		<section><title>Сохранность файлов</title>
			<para>
				Под сохранностью файлов обычно понимают шифрование и ЭЦП. Естественно, шифрования в программе <command>zz</command>
				никогда не будет — это другая задача.
			</para>
			<para>
				Однако по моему мнению, сохранность намного более широкое понятие, если речь идёт про информацию. Кроме шифрования
				для конкретного реципиента(реципиентов) и проверки подлинности, есть и ещё одна проблема: переданная информация
				может быть проанализированна по пути следования, и это почти всегда нежелательно.
			</para>
			<para>
				Речь конечно не про ББ/КГБ/ЦРУ, всё намного банальнее. Практически весь трафик на сегодня тщательно анализируется,
				индексируется и сохраняется. Особенно преуспела в этом неодназначном деле "Корпорация Добра" (aka Google, если
				кто не понял). Не отстают от неё и разная мелочь, в т.ч. и национальная, российская(yandex, mail.ru, и ещё Over9000).
			</para>
			<para>
				Все эти организации ратуют за "Открытые Системы", но дьявол в деталях: <emphasis>откуда</emphasis> и
				<emphasis>куда</emphasis> они "открыты"?
			</para>
			<para>
				Разгадка проста: открыты эти системы исключительно от вас, уважаемый читатель, и к этому вашему гуглу.
			</para>
			<para>
				А вот в обратном направлении они совсем закрытые, и мы даже толком не знаем,
				<emphasis>что</emphasis> они сохраняют. Косвенно об этом можно судить по разнообразным открытым статистикам,
				откуда очевидно, что хранится каждый ваш шаг, и каждый клик.
			</para>
			<para>
				Эта информация отнюдь не эфимерная — её можно продать, купить, а можно и украсть. Кому она достанется —
				неизвестно. Не будет преувеличением продположить, что достаться она может <emphasis>кому угодно</emphasis>.
			</para>
			<para>
				Надёжность хранения данной информации неизвестна, т.к. программный код серверных приложений закрыт и абсолютно
				недоступен (намного более недоступен, нежели код какой-нить OS Windows™, код своей ОС вы всегда можете
				просмотреть дизассемблером, но с сервером такой фокус не пройдёт). Даже если сегодня код анализаторов
				безобиден, то в любой момент без всяких предупреждений его можно изменить.
			</para>
			<para>
				Это всё не тайна, например mail.ru в EULA к своему говнооблаку русским по белому пишет, что все
				файлы в её облаке пренадлежат уже ей, а не вам. И это ещё не самый худший вариант, на самом деле,
				в маилру-облаке можно хранить зашифрованные файлы, но попробуйте проделать такое в гуглодоксах. Увы,
				в клубе лордов верят на слово…
			</para>
		</section>
		<section>
			<para>
				Избыточное кодирование может защитить от этой угрозы, причём двумя путями:
				<orderedlist>
					<listitem>
						<para>
							Прежде чем вскрывать информацию, её нужно сначала <emphasis>найти</emphasis>.
							Но поиск будет слишком сильно осложнён
							<link linkend="system_encode">несистематическим кодированием</link>, из-за которого
							статистически блоки после кодирования будут неотличимы от белого шума.
						</para>
						<para>
							Никаких ресурсов не хватит для проверки <emphasis>всех</emphasis> файлов,
							особенно учитывая, что матрицу кодирования можно выбирать почти произвольно.
						</para>
						<para>
							Конечно это не поможет (и не должно) от целенаправленной атаки на файл,
							но сделает практически невозможным поиск информации по статистическим признакам
							и сигнатурам
						</para>
					</listitem>
					<listitem>
						<para>
							Совсем не обязательно хранить на одном ресурсе весь файл, можно хранить
							неполный комплект блоков. Восстановление файла в таком случае тоже будет практически невозможно.
							(<link linkend="no_recover">См. выше</link>)
							<warning>
								Таки ещё раз напомню, что эту возможность <emphasis>не нужно</emphasis>
								использовать вместо шифрования. Для шифрования есть GnuPG.
							</warning>
						</para>
					</listitem>
				</orderedlist>
			</para>
			<para>
				Всё это поможет не только при хранении данных в сетевых хранилищах, но и при передачи данных. Пункт №2 будет
				работать потому, что путь следования пакетов в Сети трудно предсказуем, и анализировать трафик будет возможно
				лишь в двух точках, в начале и в конце пути. Однако оконечные абонентские сервера ISP и так перегружены,
				т.ч. взваливать на них такую дополнительную нагрузку никто не станет.
			</para>
		</section>
	</section>
	<section><title>Облака</title>
		<para>
			На сегодняшний день облака "в тренде". О них слышали все. Как это обычно бывает — их никто толком не видел.
			Никто толком не может даже определить это понятие, за исключением общих фраз и обещаний.
		</para>
		<para>
			На практике мы видим, что эти обещания не выполняются. Облака на сегодня очень медленно, и ненадёжно.
			Как это не печально — ещё и мало.
		</para>
		<section>
			<para>
				FIXME
			</para>
		</section>
	</section>
</chapter>
