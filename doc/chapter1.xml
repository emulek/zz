<!--DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN" "http://www.oasis-open.org/docbook/xml/4.2/docbookx.dtd"-->
<chapter id="chapter1">
	<title>
		Принцип работы
	</title>
	<para>
		<indexterm>
			<primary>Глава 1</primary>
		</indexterm>
		<para>
			<mediaobject><imageobject><imagedata fileref="apicture.png" format="png"/>
			</imageobject></mediaobject>
			В основе любой сложной системы лежит простая идея.
		</para>
	</para>
	<section id="intro"><title>Вступление</title>
		<para>
			Мне кажется, идею внесения избыточности проще всего объяснить на примере обычной <link linkend="matrix">СЛАУ</link>
			(системы линейных алгераических уравнений).
		</para>
	</section>
	<section id="matrix"><title>СЛАУ</title>
		<section>
			<para>
				←← <link linkend="begin">Начало</link>
			</para>
			<para>
				← <link linkend="intro">Глава 1, Оглавление</link>
			</para>
		</section>
		<section id="mat_intro"><title>Введение в СЛАУ</title>
			<para>
				Из школьного курса алгебры известно, что почти любую систему из N уравнений с N неизвестными
				возможно <emphasis>однозначно</emphasis> решить. Причём решение довольно простое. Конечно возможен
				случай отсутствия решения, или наличие неоднозначного решения, однако эта проблема очень хорошо
				изучена. К примеру вот система из двух уравнений:
				<para>①<programlisting>
					2*x + 3*y = 8
					3*x + 4*y = 11
				</programlisting></para>
				решив её, получаем: 
				<para>②<programlisting>
					x = 1
					y = 2
				</programlisting></para>
				Мы можем добавить ещё уравнение: 
				<para>③<programlisting>
					2*x + 3*y = 8
					3*x + 4*y = 11
					4*x + 5*y = 14
				</programlisting></para>
				Теперь, хотя в системе три уравнения, нам для решения достаточно всего двух любых.
				<note>
					Важно отметить <emphasis>произвольный</emphasis> выбор пары уравнений из трёх.
				</note>
			</para>
			<para>
				Теперь посмотрим на систему ① с другой стороны: её можно рассматривать не только как СЛАУ, но и как способ
				кодирования любых двух чисел (x,y). При этом коэффициенты (2,3,3,4) считаются изначально заданными и неизменными
				константами. А вот числа (8,11) мы будем считать результатом кодирования. Т.е. система ① является кодированной системой ②.
				Конечно в этом нет особого практического смысла, ибо системы эквивалентны.
				Однако, система ③ не является эквивалентной системам ① и ②.
				Она состоит из трёх уравнений, любой из которых можно исключить.
				Т.о. мы видим, что система ② равномерно распределена в системе
				③, и информации в системе ② ровно ⅔ от системы ③.
			</para>
			<para>Коэффициенты обозначим буквой «a», исходные данные
				«d», а результат кодировани «c». Тогда система ① запишется в таком виде:
				<para>④<programlisting>
					c₀ = d₀*a₀₀ + d₁*a₀₁
					c₁ = d₀*a₁₀ + d₁*a₁₁
				</programlisting></para>
				либо в матричной форме:
				<para><programlisting>
					C = D * A
				</programlisting></para>
				<note>
					Эта запись немного отличается от общепринятой. Во первых индекс отсчитывается от нуля(как принято
					в программировании). Во вторых, я умножаю вектор-строку D на матрицу, и получаю вектор-строку C.
					Однако в книгах удобнее рисовать вектор-столбец. 
				</note>
				Систему ④ несложно расширить до трёх и более уравнений(как система ③ ), при этом матрица станет прямоугольной,
				число строк не измениться, а столбцов будет больше.
			</para>
			<para>
				Для декодирования данных требуется просто вычислить обратную к A матрицу B = A¯¹. Тогда данные можно получить по
				формуле:
				<para>⑤<programlisting>
					D = C * B
				</programlisting></para>
				<note>
					Эта формула известна в литературе как "ключевое уравнение". Только у меня матрица B любая, а другие авторы
					используют обычно матрицу B в треугольном виде, таком, что коэффиценты b(j,k)==0, если j меньше k.
					Это не принципиальная разница. Кроме того, в других декодерах число уравнений(строк матрицы) неизвестно,
					и потому решение нетривиальное, и очень долгое.
				</note>
				Вообще говоря матрица A прямоугольная(не квадратная), и что-бы её обратить, необходимо вычеркнуть
				лишние столбцы тех данных,
				которые мы потеряли. Получается, что для декодирования необходимо и достаточно ровно столько чисел c, сколько
				было изначально данных d.
			</para>
		</section>
		<section><title>Преобразования СЛАУ</title>
			<para>
				СЛАУ вида ① можно преобразовывать, в частности, любое уравнение можно умножить на любой коэффицент. Например
				умножим первое на ⅓, а второе на ¼:
				<para><programlisting>
					2*x + 3*y = 8   |×⅓
					3*x + 4*y = 11	|×¼

					⅔*x +   y = 8/3
					¾*x +   y = 11/4
				</programlisting></para>
				получилось эквиваленное уравнение, и теперь можно вычесть из первого второе:
				<para><programlisting>
					⅔*x +   y = 8/3
				¯	¾*x +   y = 11/4

					-1/12*x   = -1/12  |×-12
					¾*x +   y = 11/4

					x         = 1
					¾*x +   y = 11/4
				</programlisting></para>
				теперь мы нашли, чему равно x. Если пойти дальше,
				<para><programlisting>
					x         = 1
					¾*x +   y = 11/4 |×4/3

					x         = 1
				¯	x + 4/3*y = 11/3

					x         = 1
					    4/3*y = 8/3  |×¾

					x         = 1
					        y = 2
				</programlisting></para>
				то мы получаем систему ②.
			</para>
		</section>
		<section id="system_encode"><title>Систематическое и несистематическое кодирование</title>
			<para>
				Несложно заметить, что выше мы преобразовали матрицу A к единичной матрице E.
				Если перед преобразованием дописать к матрице A единичную матрицу справа, и
				производить с ней все те же преобразования, то из этой единичной матрицы получится
				матрица A¯¹, обратная к A. Данный метод называется методом Гаусса, и
				именно с его помощью и решаются СЛАУ.
			</para>
			<para>
				У нас же матрица не квадратная, а прямоугольная. Обращать её в таком виде нельзя,
				однако, преобразования применять всё ещё возможно. При этом матрица преобразований численно изменяется,
				хотя все уравнения всё равно остаются эквивалентными. Очевидно, неквадратную матрицу
				невозможно сделать единичной. Однако, единичной можно сделать её левую квадратную часть. Тогда
				результаты кодирования c(0,1,…,k) будут равны исходным данным d(0,1,…,k). Результат кодирования c(0,1,…,n)
				будет совпадать с исходными данными в первых k числах. Такое кодирование называется
				<emphasis>систематическим</emphasis>.
			</para>
			<para>
				При <emphasis>несистематическом</emphasis> кодировании матрица не является "частично-единичнй",
				потому выходные данные не имееют ничего общего с входными.
				<note>
					Важно отметить, что "частично-единичная" матрица единственна, а вот остальных
					матриц(эквивалентных) практически бесчисленное множество (множество на самом деле конечно,
					но ОЧЕНЬ большое).
				</note>
			</para>
			<para>
				я применяю именно несистематическое кодирование, причины следующие:
				<itemizedlist>
					<listitem>
						<para>
							Нет никаких оснований делать блоки разными. Проще и надёжнее сделать их одинаковыми для
							того, что-бы можно было-бы их принимать/отправлять без всякого контроля(который обычно
							и не возможен).
						</para>
					</listitem>
					<listitem>
						<para>
							Процедура нисестематического кодирования является ещё и процедурой рандомизации
							("ослучаивания"). Статистически выход кодера представляет собой белый шум,
							с хорошей статистикой. Такую передачу невозможно детектировать, т.к. она
							не содержит, и не может содержать каких-то сигнатур годных для анализа.
							Естественно это не поможет от целенаправленного прослушивания данного канала,
							однако, канал передачи ещё нужно и найти. Нисистематическое кодирование
							эту задачу существенно осложняет, даже если <emphasis>враг</emphasis> в курсе,
							какие именно данные идут по каналу.
						</para>
					</listitem>
					<listitem>
						<para>
							Первые системы кодирования с избыточностью(кодирование Рида-Соломона например)
							применялись ещё и потому, что техника тех лет была очень слабой — если канал
							не очень шумный, то данные шли по большей части AS IS, и декодер просто игнорировал
							доболнительные символы, если данные были целы в основных. В итоге, декодер
							работал очень нестабильно: обычно данные текут хорошо и быстро, но иногда возникают
							"затыки", когда появляется ошибка, и вот тут декодеру приходится напрягаться,
							в поисках нужных битов, закопаных в контрольных суммах. На практике выигыша никакого
							и нет, т.к. "затыки" появляются неумолимо и неизбежно, в полном соответствии с
							теорией вероятности. Потому выигрыш в производительности на 95% данных полностью съедается
							теми самыми 5%, обработка которых требует всех вычислительных ресурсов.
						</para>
						<para>
							ИМХО проще тратится на фиксированное и известное время декодирования,
							чем надеяться на случайность.
						</para>
					</listitem>
				</itemizedlist>
				Из за несистематического кодирования, моему декодеру абсалютно всё равно, какие именно данные
				будут на входе.
			</para>
		</section>
		<section><title>Зачем нужны матрицы?</title>
			<para>
				Матрицы позволяют унифицировать вычисления. На практике всегда известно, какой блок приехал с ошибкой, а какой
				целый. Вместо того, что-бы разбираться с каждым блоком по отдельности, декодер формирует одну единственную матрицу
				переобразования для всей части данных.
			</para>
			<para>
				Время вычисления обратной матрицы большое(O(n³)), однако время самого преобразования незначительно(фиксированное
				количество умножений/сложени, на практике у меня не больше 15 на цифру). Таким образом, после анализа полученных
				блоков, декодер строит шаблон преобразования(декодирующую матрицу), который затем и использует для
				извлечения данных.
			</para>
		</section>
		<section><title>Выбор кодирующей матрицы</title>
			<para>
				Важно выбрать такую кодирующую матрицу, которая не будет <emphasis>выраждаться</emphasis>(т.е. можно
				будет вычислить обратную к ней после вычёркивания столбцов соответствующих потерянным данным). Эта
				задача мне показалась особенно сложной, однако по счастью, математики её давно решили.
				Матрица Мандельброта представляет собой матрицу, в которой каждая строка представляет собой разную
				степень разных чисел.
			</para>
			<para>
				К примеру:
				<programlisting>
					|  1  2  4   8 |
					|  1  3  9  27 |
					|  1  4 16  64 |
					|  1  5 25 125 |
				</programlisting>
				Несложно доказать, что такого вида матрица никогда не выраждается, сколько-бы(и каких)
				строк/столбцов из неё не вырезали.
			</para>
		</section>
		<section>
			<para>
				← <link linkend="intro">Оглавление</link>
				<link linkend="arithm">Арифметика в полях Галуа</link> →
			</para>
		</section>
	</section>
	<section id="arithm"><title>Арифметика в полях Галуа</title>
		<section>
			<para>← <link linkend="matrix">СЛАУ</link></para>
			<para><link linkend="intro">Оглавление</link></para>
		</section>
		<section id="arithm_intro"><title>Вступление</title>
			<para>
				Выше было рассказано, как можно было-бы кодировать информацию
				<warning>
					Угу. Было-бы. Но НЕЛЬЗЯ. К сожалению, всё вышеизложенное не имеет никакого практического
					смысла, а лишь голая, и неприменимая на практике теория. Проблема в самиих числах,
					которые я выше предполагал "математическими числами", т.е некой абстрактной моделью,
					в которой нет изьяна.
				</warning>
			</para>
			<para>
				К моему огромному сожелению, в обычных числах, есть один "маленький" недостаок: ИХ НЕТ.
			</para>
		</section>
		<section><title>Те числа, о которых мы думали, что мы их имели</title>
			<section><title>Натуральные числа</title>
				<para>
					Начнём мы с начала, а именно с натуральных чисел, т.е. с чисел 1,2,3,4,5…
					<note>
						Будем считать, что 0 не входит в множество натуральных чисел.
					</note>
				</para>
				<para>
					Проблема кроется в их информационном наполнении. Натуральные числа бесконечны. Это не создаёт особых проблем,
					пока мы работаем с кольцом ограниченным сложением. И более того: наше кольцо натуральных чисел
					обладает свойством <emphasis>упорядоченности</emphasis>, т.е. мы знаем, какое из них больше, а какое
					меньше. Это кажется вполне естественным, и логичным.
				</para>
				<para>
					Если сложить пару натуральных чисел, то результат операции почти также наполнен информацией,
					как и аргументы. Точнее, сумма двух натуральных чисел размера N бит занимает N или N+1 бит.
				</para>
				<para>
					Таким образом, мы можем свободно складывать натуральные числа, не боясь переполнения или ещё
					каких-то проблем.
					<note>
						<para>
							Кольцом называется множество чисел, которое <emphasis>замкнуто</emphasis> по отношению к
							некоторой операции, в данном случае по отношению к сложению.
							Множество образует кольцо тогда, когда результат замыкающий операции всегда определён во множестве
							аргументов.
						</para>
						<para>
							Т.е. для натуральных чисел, результат сложения всегда определён, и
							кроме того является натуральным числом.
						</para>
					</note>
					<warning>
						Это определение необходимо, но недостаточно. На самом деле,
						множество натуральных чисел кольцом не является.
					</warning>
				</para>
			</section>
			<section><title>Целые числа</title>
				<para>
					Для образования кольца одной <emphasis>внешней</emphasis> замкнутости недостаточно.
					Множество должно быть замкнуто <emphasis>внутренне</emphasis>. Т.е. если мы идём по множеству "вперёд",
					то мы могли-бы и вернуться "назад", причём <emphasis>однозначно</emphasis>.
				</para>
				<para>
					Множество натуральных чисел таким свойством НЕ обладает: "вперёд" мы можем идти всегда, а вот
					"назад" — увы. Например, непонятно, что было 10 единиц назад от 3?
				</para>
				<para>
					Это не сложно исправить, расширив множество натуральных чисел "вниз", "до" единицы.
				</para>
				<para>
					Получится множество <emphasis>целых</emphasis> чисел: 0, ±1, ±2, ±3….
				</para>
				<para>
					Такое множество целых является полноценным кольцом, с однозначным сложением,
					и с однозначным <emphasis>вычитанием</emphasis>, т.е. операцией, которая является
					взаимообратной к сложению.
				</para>
			</section>
			<section><title>Нейтральный элемент</title>
				Кольцо целых имеет единственный нейтральный элемент — ноль. После сложения/вычитания с ним,
				любой элемент множества <emphasis>неизменяется</emphasis>.
				<warning>
					Это порождает неоднозначность, ведь если изменения нет, то любая операция
					не имеет никакого эффекта, а значит, обратить её невозможно.
					Невозможно даже узнать, была опрация, и если была, то сколько раз?
				</warning>
			</section>
			<section><title>Умножение</title>
				<para>
					Умножение в целых числах определяется рекурсивно, как сложение над сложением:
					для умножения X на Y, требуется сложить сложения X с самим собой Y раз.
				</para>
				<para>
					Наверное это не очень внятное объяснение умножения, но дальше вы сами увидите,
					что оно и не самое верное. Что на самом деле есть умножение — сказать сложно.
					Я думаю, что выше выведенное невнятное рекурсивное объяснение отображает саму суть
					умножения.
				</para>
				<para>
					И тем не менее, для целых чисел всё проще: каждое целое число представляет
					собой не только <emphasis>символ</emphasis>, но и <emphasis>номер</emphasis>,
					который можно использовать: к примеру, число 17 это не только 17, но и некая
					абстракция, которая задаёт 17 одинаковых объектов/действий, ну например
					^^^^^^^^^^^^^^^^^. Тут 17 символов «^».
				</para>
				<para>
					Мы не можем надеяться, что это верно в любых множествах, но во множестве
					целых это так. Потому(и только по этому) мы можем чётко определить умножение,
					как многократное сложение над кольцом целых чисел.
				</para>
				<para>
					Невнятное определение — это самая меньшая беда умножения. Куда как хуже её
					информационное поведение. При прямом умножении в кольце целых информация произведения
					УВЕЛИЧИВАЕТСЯ. Т.е. каждый бит при умножении двух чисел УДВАИВАЕТСЯ.
				</para>
				<para>
					Т.о. после 10(десяти) умножений, количество информации возрастёт в миллион раз,
					точнее в 1`048`576 раз.
					<note>
						Конечно такая беда постигнет лишь позиционные системы счисления вроде
						десятичной, двоичной, шеснадцетеричной и так далее. Можно придумать систему счисления,
						в которой такой беды нет. Проблема в том, что там другие беды. Впрочем, мы сейчас
						этим и займёмся…
					</note>
				</para>
				<para>
					Проблема даже не в самом это увеличении количества информации, проблема в том, что на
					самом деле количество информации не слишком-то увеличивается.
				</para>
				<para>
					На первый взгляд, это звучит бредом: число бит <emphasis>необходимых</emphasis> для записи
					произведения удваивается, но число информации — нет? Разгадка кроется в <emphasis>энтропии</emphasis> произведения.
					<note>
						Энтропия — мера хаоса, другими словами, неопределённость. Что-бы "орпределится", т.е.
						получить информацию, нам требуется убрать неопределённость. К примеру энтропия монетки
						(точнее одного браска идеальной монетки в сферическом вакууме) равна ровно 1 биту. Что-бы
						узнать, какой стороной упала монетка, нам нужно <emphasis>получить</emphasis> этот бит.
						Клод Шенон давно уже вывел формулу вычисления энтропии любых "монеток":
						<para>⑥<programlisting>
								E = -p*log₂(p)
						</programlisting></para>
						Здесь «p» представляет собой <emphasis>вероятность</emphasis> события, и если мы хотим
						получить энтропию в битах, то логарифм надо брать по основанию 2.
					</note>
				</para>
				<para>
					Что-бы вычислить энтропию множества событий, нужно сложить энтропии всех событий из множества.
					К примеру, если у нас есть 65536 независимых и равнвероятных событий, то энтропия получается равной:
					65536*(-1/65536*log₂(1/65536))=16бит. Т.е. для передачи реципиенту результата такого эксперимента, донору
					необходимо и достаточно послать ровно 16бит, что не удивительно, т.к. каждое событие можно взаимооднозначно
					сопоставить с числом от 0 до 2¹⁶-1.
				</para>
				<para>
					При умножении двух чисел {0..255} (здесь и далее эта запись значит: числа от 0 до 255 включительно) получается число
					{0..65025}, т.е. практически {0..65536} (в пределе, при стремлении множителей к бесконечности, мощность
					множества произведений стремится к квадрату мощности множеств). И на первый взгляд кажется, что нам нужно почти 16бит
					для записи произведения. Но применяя формулу Шеннона мы видим, что энтропия множества равна 13.705бит, а не 16бит.
					Причина этого в том, что произведений намного меньше 65536, а именно 17578 (например в нашей таблице
					отсутствует число 257). Кроме того некоторые числа встречаются чаще других, т.е. вероятность произведений
					разная.
				</para>
				<para>
					Т.е. мы видим, что записать произведение можно меньшим числом бит, при этом сохранив однозначность.
					Проблема в том, что "можно" вовсе не означает "легко и быстро". Стоимость сжатия на порядки превосходит
					стоимость умножения. К тому же, эти сжатые произведения уже нельзя напрямую складывать/вычитать.
				</para>
				<para>
					Вторая беда умножения — это невозможность обратной операции в общем случае.
				</para>
				<para>
					Действительно, любо число можно умножить, но не любое можно поделить, оставаясь в кольце. Даже
					в самом начале кольца, такие числа как ½, или ¾ непредставимы.
				</para>
			</section>
			<section><title>Рациональные числа</title>
				<para>
					Естественным расширением множества целых, следует считать рациональные. Действительно,
					почему нет? К сожалению: no way. Получив простое сложение и деление, мы лишаемся сложения/вычитания,
					точнее эти операции становяться слишком дороги: либо мы экспоненциально увеличиваем их сложность
					(т.е. нас постигает та же беда, что с умножением в кольце целых), либо
					мы вынуждаем себя факторизировать числа, что не менее дорого.
				</para>
			</section>
		</section>
		<section><title>Конечные множества: кольца вычетов и поля Галуа</title>
			<section><title>Зачем?</title>
				<para>
					Переход от бесконечных к конечным множествам диктуется суровой реальностью: у нас тупо нет этих
					ваших бесконечных множеств, это всего-лишь химера, придуманная нами для простоты рассуждений.
				</para>
			</section>
			<section><title>Кольцо вычетов</title>
				<para>
					Вполне естественным следует считать, что если у нас всего 4 бита, то после числа
					1111₂ идёт число 0000₂. Это хороший выбор, ведь если "не переходить границу", то
					наши числа ведут себя как будто обычные, целые, во всяком случае при сложении. Да и сама
					"граница" вполне естественна: например после 23 часов идёт не 24, а 00 часов.
				</para>
				<para>
					Да и вообще, эти <emphasis>вычеты</emphasis> встречаются чуть-ли не на каждом шагу.
				</para>
				<para>
					Первая проблема подкрадывается неожиданно: мы теряем свойство <emphasis>упорядоченности</emphasis>
					множества. Т.е. значки "меньше" и "больше" уже не работают: 1111₂ "больше" 1110₂, а 0000₂ "больше" 1111₂.
					С другой стороны, 0000₂ "меньше" 1111₂…
				</para>
				<para>
					Всегда надо следить, не перешли-ли мы "границу"?
				</para>
				<para>
					Впрочем, эта точка в нашем кольце единственна, и проблема решаема.
					<note>
						Цена правда велика: для чисел {0..255} сплошь и рядом гоняют кольцо {-2147483648..2147483648}, если
						не больше. Ну да ладно, компьютеры у нас быстрые.
					</note>
				</para>
				<para>
					Вторая проблема серьёзнее: вычеты лишают нас умножения. Точнее, то "умножение", что есть в вычетах,
					почти совершенно бесполезно, и не имеет ничего общего с настоящим умножением. Умножение в целых в 32 бита
					работает как надо лишь на маленьком кусочке множества, когда множители ограничены {0..65536}, что на
					сегодня чуть меньше, чем ничто.
				</para>
				<para>
					"Благодоря" этому, вся арифметика в целых на сегодня ограничена тривиальными дествиями, вроде "досчитать от 1 до 100",
					или типа того…
				</para>
				<para>
					Для вычислений требуется плавующая точка, но и она не слишком годна из-за практически нерасширяемости.
				</para>
				<para>
					Попытка использовать "умножение", которое у нас есть, обречена на провал потому, что кольцо — не поле.
					К примеру в кольце Z₁₂ получается 3*4=0; 6*2=0, т.е. посредине "поля" мы получаем няшные
					<emphasis>делители нуля</emphasis>. Их няшность состоит в том, что нет никакой возможности поделить этот
					ноль на что-то другое: результат вовсе не однозначно равен нулю, как в обычных числах.
				</para>
			</section>
			<section><title>Поля Галуа</title>
				<para>
					Проблема устранима, если взять кольцо вычетов с модулем равным простому числу, к примеру Z₇.
					В этом случае множество является полем, и умножение вполне взаимооднозначно. Т.е. делителей
					нуля не появляется(кроме самого нуля конечно). Составим таблицу умножения в GF₇:
					<para>⑦<programlisting>
							0 0 0 0 0 0 0
							0 1 2 3 4 5 6
							0 2 4 6 1 3 5
							0 3 6 2 5 1 4
							0 4 1 5 2 6 3
							0 5 3 1 6 4 2
							0 6 5 4 3 2 1
					</programlisting></para>
					Во первых, прямо из таблицы видна взаимооднозначность данного умножения: все числа в любой строке(и столбце,
					кроме конечно нуля) разные. Из этого следует то, что для любого произведения и и множителя, мы можем
					найти множимое. Т.о. мы получили <emphasis>однозначное</emphasis> деление(исключая конечно
					деление на ноль. Делить на ноль можно, полученный "результат" следует трактовать как "одно любое из чисел
					Z₇ взятое с равной вероятностью". Конечно польза от такого "результата" обычно(но не всегда!)
					сомнительна).
				</para>
				<para>
					Определив умножение, мы можем возводить в степень разные числа, получается:
					<para>⑧<programlisting>
							  n| 1 2 3 4 5 6
							  ——————————————
							1^n| 1 1 1 1 1 1
							2^n| 2 4 1 2 4 1
							3^n| 3 2 6 4 5 1
							4^n| 4 2 1 4 2 1
							5^n| 5 4 6 2 3 1
							6^n| 6 1 6 1 6 1
					</programlisting></para>
					Результат интересен в первую очередь столбцом 3^n и 5^n, т.к. все числа в этих столбцах разные. Значит,
					в нашем поле с этими основаниями, мы можем определить не только однозначное возведение в степень,
					но и однозначное логарифмирование. Такие числа называются <emphasis>первообразными</emphasis>.
				</para>
				<para>
					В старину говорили: "логорифмирование удлинняет жизнь математиков", сейчас можно сказать,
					что оно же ускоряет наши компьютеры: действительно, используя таблицу логарифмов
					(у нас в ней всего 6 чисел), можно свести умножение/деление к сложению/вычитанию.
				</para>
				<para>
					К примеру, взяв по традиции последнюю годную строку из ⑧, мы получаем
					log₅(6*6)=log₅6+log₅6=3+3=6, откуда 6*6=5^6=1.
				</para>
				<para>
					Другой пример: log₅(2/3)=log₅2-log₅3=4-5=-1=-1+6=5, откуда 2/3=5^5=3. В этом примере мы возвращаем
					-1 в наше множество прибавляя 6 (а не наш модуль 7) потому, что таблица логарифмов НЕ содержит log₅0,
					и таким образом на 1 меньше модуля 7.
					<note>
						Дело в том, что не существует степени, возводя в которую мы получем 0. Потому log₅0 не существует.
						При делении, мы вычитаем логарифмы, т.е. движемся влево в таблице логарифмов. Если таблица закончилась
						(левее log₅1), то мы должны сразу перепрыгнуть log₅0, на log₅6.
					</note>
				</para>
			</section>
			<section><title>Пример кодирования и декодирования над полем Галуа GF₇</title>
				<para>
					Выберем следующую матрицу кодирования:
					<para>⑨<programlisting>
							|1 2|
							|1 3|
							|1 4|
					</programlisting></para>
					Также выберем d₀=3 и d₁=4.
				</para>
				<para>
					Тогда закодированная информация будет определятся следующими тремя уравнениями:
					<para><programlisting>
							1*d₀ + 2*d₁ = c₀ = 1*3 + 2*4 = 4
							1*d₀ + 3*d₁ = c₁ = 1*3 + 3*4 = 1
							1*d₀ + 4*d₁ = c₂ = 1*3 + 4*4 = 5
					</programlisting></para>
					Тут нам потребовалось для кодирования всего 2*3 умножений и 3 сложений.
				</para>
				<para>
					Также предположим, что до реципиента дошли лишь блоки c₁ и c₂.
				</para>
				<para>
					Больше всего времени потребуется для вычисления обратной матрицы. Но эти вычисления не влияют на скорость,
					т.к. выполнять их надо лишь 1 раз для каждой части(в каждой части содержаться тысячи и десятки тысяч
					чисел). Обратим матрицу, полученную из ⑨ вычёркиванием первой строки:
					<para><programlisting>
							|1 3| |1 0|
							|1 4| |0 1| -

							|1 3| |1 0|
							|0 1| |6 1| ×3

							|1 3| |1 0| -
							|0 3| |4 3|

							|1 0| |4 4|
							|0 3| |4 3| ×5 (тоже самое, что и ×⅓)

							|1 0| |4 4|
							|0 1| |6 1|.
					</programlisting></para>
					Зная обратную матрицу, мы можем восстановить данные:
					<para><programlisting>
							d₀ = 4*c₁ + 4*c₂ = 4*1+4*5 = 3
							d₁ = 6*c₁ + 1*c₂ = 6*1+1*5 = 4
					</programlisting></para>
					Для декодирования вновь потребовалось 2*3 умножений и 3 сложения, как и при кодировании. Т.о. мы видим,
					что время кодирования и декодирования совпадает, и не зависит от входных данных.
				</para>
				<para>
					Если-бы реципиент получил-бы блоки c₀ и c₁ нужно было-бы обратить матрицу
					<para><programlisting>
							|1 2| → |3 5|
							|1 3|   |6 1|
					</programlisting></para>
					Но результат-бы естественно не изменился:
					<para><programlisting>
							d₀ = 3*c₀ + 5*c₁ = 3*4+5*1 = 3
							d₁ = 6*c₀ + 1*c₁ = 6*4+1*1 = 4
					</programlisting></para>
				</para>
			</section>
			<section id="no_recover"><title>Невозможность восстановления данных при недостаточном количестве блоков</title>
				<para>
					Очевидно, если поступивших блоков недостаточно, то восстановление данных невозможно. Мало того,
					мы даже <emphasis>не сможем восстановить хотя бы один блок</emphasis>.
				</para>
				<para>
					Для примера, рассмотрим, что произойдёт при получении лишь блока c₁=1. Попробуем угадать блок c₀
					<para><programlisting>
							c0=0, d0=5, d1=1
							c0=1, d0=1, d1=0
							c0=2, d0=4, d1=6
							c0=3, d0=0, d1=5
							c0=4, d0=3, d1=4
							c0=5, d0=6, d1=3
							c0=6, d0=2, d1=2
					</programlisting></para>
					Мы получили 7 равновероятных пар (d₀,d₁). Попытка угадать блок c₂ даст те же пары
					<para><programlisting>
							c2=0, d0=4, d1=6
							c2=1, d0=1, d1=0
							c2=2, d0=5, d1=1
							c2=3, d0=2, d1=2
							c2=4, d0=6, d1=3
							c2=5, d0=3, d1=4
							c2=6, d0=0, d1=5
					</programlisting></para>
					только в другом порядке.
				</para>
				<para>
					Таким образом, если знать лишь один блок из двух необходимых, то это не позволит узнать даже
					один какой-то блок, а только 7 равновероятных пар блоков.
				</para>
			</section>
			<section><title>Практическая реализация матрицы кодирования и выбор GF</title>
				<para>
					Над этим полем(GF₇) можно реализовать лишь кодирование с избыточностью 150%. Этого недостаточно для практике.
					На практике модуль GF выбран равным 1399, что позволяет построить матрицы 15×7(избыточность 214%, 200%, 186%,
					171%, 157%, 143%, 129%, и 114%), например для избыточности 157% реципиенту отправляется не 15 блоков, а всего 11.
					Для ещё большего увеличения избыточности берёться не 7, а меньше входных блоков, т.о. получается избыточность
					300% и более.
				</para>
			</section>
			<section><title>Другие поля Галуа</title>
				<para>
					В других декодерах(e.g. код Рида-Соломона) используются поля Галуа с составным(а не простым, как у меня)
					модулем. Такое поле можно построить для любого модуля вида p^q, где p — простое число, а q — любое целое
					больше 1(при q=1 получается вышерассмотренное GF с простым модулем).
				</para>
				<para>
					Этот выбор имеет существенный плюс, т.к. коды можно строить прямо над машинными числами с модулем 2^q.
				</para>
				<para>
					Умножение в таком поле осуществляется также путём логарифмирования, и потенциирования. Но вот сложение
					требуется выполнять по модулю p=2. ИМХО это не самый лучший выбор, т.к. операция XOR довольно плохо перемешивает
					биты. По моему мнению есть смысл перейти к простым числам, и проводить операции там. Это конечно дороже,
					однако современные компьютеры намного быстрее считают, нежели сохраняют, а уж тем более передают
					информацию по существующим каналам.
				</para>
			</section>
		</section>
		<section>
			<para>
				<link linkend="chapter2">Реализация</link> →
			</para>
		</section>
	</section>
</chapter>
